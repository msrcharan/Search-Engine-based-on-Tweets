# -*- coding: utf-8 -*-
"""BM25_Final+GUI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nIPmChFTv5kvFu_TQrWu3pIDHb9MDMhN
"""

pip install rank_bm25

print(file_subset[2001])

from google.colab import drive
drive.mount('/content/drive')

# f=file_subset[2000]
f = open(file_subset[2000], 'r')

content = f.read()
tokenized_corpus = content.split(" ")
print(tokenized_corpus)
f.close()

import os
from nltk.tokenize import word_tokenize

# List the files in the directory
# file_list = os.listdir('/content/drive/MyDrive/tweet_files')
data_dir = '/content/drive/MyDrive/tweet_files/'
DATA_SET_DIR = data_dir
print('\nGetting List of text files from' + DATA_SET_DIR)
files = os.listdir(DATA_SET_DIR)
print((files[11]))
print('\nFile list retrieved from ' + DATA_SET_DIR)

from typing_extensions import Concatenate
corpus = []
for f in files:
  strm = open(DATA_SET_DIR + f,'r')
  content = strm.read()
  words = content.split(" ")
  corpus.append(' '.join(words))
  strm.close()

print(corpus[11])

from rank_bm25 import BM25Okapi #imp copy from here
def bm25_precision10(query, corpus):
    tokenized_corpus = [doc.split(" ") for doc in corpus]
    bm25 = BM25Okapi(tokenized_corpus)
    tokenized_query = query.split(" ")
    doc_scores = bm25.get_scores(tokenized_query)
    print("Top relevant docs are :")
    print(bm25.get_top_n(tokenized_query, corpus, n=5))
    print("Top 10 relevant docs in the query :")
    docscores = list(doc_scores)
    topten = sorted(range(len(docscores)), key=lambda i: docscores[i], reverse=True)[:10]
    print(topten)

bm25_precision10("football",corpus)

pip install PySimpleGUI

import matplotlib
matplotlib.use('Agg')

import PySimpleGUI as sg

layout = [
    [sg.VPush()],
    [sg.Text("Search: "), sg.Input(key='INPUT')], 
    [sg.Ok()],
    [sg.Text("", size=(0, 1), key='OUTPUT'),  ],
    [sg.VPush()],
]

window = sg.Window("Tweets Database", layout, size=(1400, 600), element_justification='c',background_color='white')

while True:
    event, values = window.read()
    if event == sg.WINDOW_CLOSED:
        break
    elif event == 'Ok':
        name = values['INPUT']
        tokenized_query = name.split(" ")
        doc_scores = bm25.get_scores(tokenized_query)
        window['OUTPUT'].update(value=bm25.get_top_n(tokenized_query, corpus, n=1))

window.close()

pip install aiml

bm25 = BM25Okapi(corpus)
scores = bm25.get_scores("football")
ranked_files = sorted(zip(file_list, scores), key=lambda x: x[1], reverse=True)
for file, score in ranked_files[:10]:
  print(f'{file}: {score}')

